{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: black==22.10.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (22.10.0)\n",
      "Requirement already satisfied: numpy==1.21.6 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
      "Requirement already satisfied: Flask==2.2.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: pymongo==3.12.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (3.12.0)\n",
      "Requirement already satisfied: Python-dotenv==0.21.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: Flask-Cors==3.0.10 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.0.10)\n",
      "Requirement already satisfied: Flasgger==0.9.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.9.5)\n",
      "Requirement already satisfied: Pydantic==1.9.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (4.2.0)\n",
      "Requirement already satisfied: keybert==0.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: pandas==1.3.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (1.3.5)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (2.5.0)\n",
      "Requirement already satisfied: scispacy==0.5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (4.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (2.5.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (0.10.1)\n",
      "Requirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black==22.10.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask==2.2.2->-r requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from Flask==2.2.2->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from Flask==2.2.2->-r requirements.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flask==2.2.2->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: Six in /opt/conda/lib/python3.7/site-packages (from Flask-Cors==3.0.10->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: mistune in /opt/conda/lib/python3.7/site-packages (from Flasgger==0.9.5->-r requirements.txt (line 7)) (2.0.4)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flasgger==0.9.5->-r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from Flasgger==0.9.5->-r requirements.txt (line 7)) (4.16.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0->-r requirements.txt (line 10)) (1.7.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0->-r requirements.txt (line 10)) (5.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.7/site-packages (from keybert==0.7.0->-r requirements.txt (line 11)) (1.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /opt/conda/lib/python3.7/site-packages (from keybert==0.7.0->-r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: rich>=10.4.0 in /opt/conda/lib/python3.7/site-packages (from keybert==0.7.0->-r requirements.txt (line 11)) (12.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.3.5->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.3.5->-r requirements.txt (line 12)) (2022.5)\n",
      "Requirement already satisfied: conllu in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (4.5.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (1.2.0)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (3.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (2.28.1)\n",
      "Requirement already satisfied: nmslib>=1.7.3.6 in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: pysbd in /opt/conda/lib/python3.7/site-packages (from scispacy==0.5.1->-r requirements.txt (line 14)) (0.3.4)\n",
      "Requirement already satisfied: dnspython<2.0.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from pymongo==3.12.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 13)) (2.4.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 13)) (2.8.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 13)) (2.13.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage->-r requirements.txt (line 13)) (2.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->-r requirements.txt (line 13)) (1.56.4)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->-r requirements.txt (line 13)) (4.21.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 13)) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 13)) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 13)) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage->-r requirements.txt (line 13)) (1.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask==2.2.2->-r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->Flask==2.2.2->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->Flasgger==0.9.5->-r requirements.txt (line 7)) (22.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->Flasgger==0.9.5->-r requirements.txt (line 7)) (5.10.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->Flasgger==0.9.5->-r requirements.txt (line 7)) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->Flasgger==0.9.5->-r requirements.txt (line 7)) (0.18.1)\n",
      "Requirement already satisfied: pybind11<2.6.2 in /opt/conda/lib/python3.7/site-packages (from nmslib>=1.7.3.6->scispacy==0.5.1->-r requirements.txt (line 14)) (2.6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from nmslib>=1.7.3.6->scispacy==0.5.1->-r requirements.txt (line 14)) (5.9.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1->-r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1->-r requirements.txt (line 14)) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1->-r requirements.txt (line 14)) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1->-r requirements.txt (line 14)) (3.4)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert==0.7.0->-r requirements.txt (line 11)) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert==0.7.0->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert==0.7.0->-r requirements.txt (line 11)) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (4.64.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (3.7)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (0.13.1+cu113)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (1.12.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (0.10.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (0.1.97)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (59.8.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (2.4.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (8.1.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (3.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (0.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (2.0.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage->-r requirements.txt (line 13)) (1.15.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r requirements.txt (line 13)) (0.4.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1->-r requirements.txt (line 14)) (0.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (0.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert==0.7.0->-r requirements.txt (line 11)) (9.2.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage->-r requirements.txt (line 13)) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to DB\n"
     ]
    }
   ],
   "source": [
    "from persistence import Connection as Database\n",
    "db: Database = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = db.fetch_all_unlabeled_resumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "resume = {}\n",
    "\n",
    "with open(\"demo/ds10_modified.json\") as f:\n",
    "    resume = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': [{'value': {'company': 'Apple',\n",
       "    'title': 'Data Scientist',\n",
       "    'location': 'San Francisco',\n",
       "    'fromDate': 'June 2022',\n",
       "    'toDate': 'Present',\n",
       "    'description': ''},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'iRobot',\n",
       "    'title': 'Data Scientist',\n",
       "    'location': 'Boston',\n",
       "    'fromDate': 'August 2021',\n",
       "    'toDate': 'May 2022',\n",
       "    'description': 'Developing data mining solutions to create practical insights for optimizing Direct-to-Customer plans and activities. Improving product quality by analyzing customer and product data to identify issues and improvement areas. Built a 52% more accurate demand and sales forecasting model through better model selection and feature engineering. Producing dashboards and Decision Support Systems to help stakeholders in data-driven decision-making'},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'UMass Boston College of Management',\n",
       "    'title': 'Graduate Research Assistant',\n",
       "    'location': 'Boston',\n",
       "    'fromDate': 'September 2016',\n",
       "    'toDate': 'August 2021',\n",
       "    'description': 'In my research, I design experiments, conduct exploratory data analysis, apply statistical methods, and develop Machine Learning models to study human behaviors and to produce results with practical insights of value in a business context. Built an ML pipeline to predict online review effectiveness through personalization and feature engineering with NLP (Python). Applied NLP to extract new features through sentiment analysis and topic modeling (NLTK & Gensim). Developed XGBoost, Random Forest, and Poisson Regression (log-linear) models to predict customers decision. Developed and enhanced time series and RNN models of sequential human decisions through behavioral modeling (Python). Built and tuned ARIMA and LSTM models using new behavioral features and improved prediction RMSE by 5.8% (statsmodels & sklearn & keras). Developed a stock market portfolio recommender model using cluster analysis and association rule mining (R & SQL).'},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'Babson College',\n",
       "    'title': 'Quantitative Methods Fellow',\n",
       "    'location': 'Wellesley',\n",
       "    'fromDate': 'August 2020',\n",
       "    'toDate': 'May 2021',\n",
       "    'description': 'Teaching courses in Quantitative Methods, Business Analytics, Data Mining, and Statistical Learning'},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'Plymouth Rock Assurance',\n",
       "    'title': 'Data Science Intern',\n",
       "    'location': 'Boston',\n",
       "    'fromDate': 'July 2020',\n",
       "    'toDate': 'January 2021',\n",
       "    'description': \"I was using the company's big data to build advanced analytical solutions and Machine Learning models to improve the predictive performance of the risk and pricing models. Improved performance of the XGBoost model for price & risk prediction through feature engineering (Python, SAS). Decreased unmatched customer records by 42% by performing entity resolution (Python, SQL, SAS)\"},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'Hamrahe Aval (MCI)',\n",
       "    'title': 'Product Development Specialist',\n",
       "    'location': 'Tehran',\n",
       "    'fromDate': 'February 2016',\n",
       "    'toDate': 'August 2016',\n",
       "    'description': \"I was responsible for improving business performance by building analytical models and tools to create data-driven business solutions and data-informed strategies. Developed machine learning models to predict customer lifetime value and churn using big data of customers and market (R). Built predictive models and created plans based on their results to maximize productivity and minimize costs (SQL & R). Managed cross-functional project of business process improvement and ERP system development. Designed and developed BI dashboards and a Decision Support System for data-driven decision-making: Developed a fully in-house system to address the company's specific needs in terms of financial management, provider network management, customer relationship management (CRM), and operations management.\"},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'Trigo',\n",
       "    'title': 'Master Thesis Writer',\n",
       "    'location': 'Oslo',\n",
       "    'fromDate': 'January 2013',\n",
       "    'toDate': 'June 2013',\n",
       "    'description': 'Used Keras and YOLO in embedded systems to do object recognition in rounabouts. The results were sent to GCP where they where further analyzed with high dimension classifiers.'},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'FANAP',\n",
       "    'title': 'Business Intelligence Specialist',\n",
       "    'location': 'Tehran',\n",
       "    'fromDate': 'September 2011',\n",
       "    'toDate': 'December 2012',\n",
       "    'description': 'I was responsible for improving business performance by building analytical models and tools to create data-driven business solutions and data-informed strategies. Designed and developed BI dashboards as well as fully in-house system to address the companyâ€™s specific needs in terms of financial management, provider network management, customer relationship management (CRM), and operations management'},\n",
       "   'label': 0},\n",
       "  {'value': {'company': 'Pdhco - Print & Design',\n",
       "    'title': 'Product and Market Development Specialist',\n",
       "    'location': 'Tehran',\n",
       "    'fromDate': 'September 2011',\n",
       "    'toDate': 'December 2012',\n",
       "    'description': \"I was responsible for growing the company's revenue and its market share by creating data-driven insights that help the company improve its marketing strategies and product-market fit.\"},\n",
       "   'label': 0}],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\n",
    "with open(\"jd_examples/DS_JD2.txt\", 'r') as f:\n",
    "    job_description = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Job\n",
    "importlib.reload(Job)\n",
    "Job = Job.Job\n",
    "from model.keyword_utils import extract_requirements_JD\n",
    "\n",
    "from persistence.cloud_storage.cloud_storage import read_job_keywords\n",
    "from util.json_to_df import create_df, get_resume_dict_from_dataframe\n",
    "\n",
    "job_title = \"Data Scientist\"\n",
    "description_keywords = extract_requirements_JD(job_description)\n",
    "job_keywords_csv = read_job_keywords(job_title)\n",
    "job = Job(job_title)\n",
    "job.load_from_csv_data(job_keywords_csv)\n",
    "\n",
    "orig_keywords = set(job.keywords.keys())\n",
    "jd_keyword_set = set(description_keywords)\n",
    "kw = list(orig_keywords.intersection(jd_keyword_set))\n",
    "\n",
    "job.update_keywords_from_description(description_keywords)\n",
    "\n",
    "\n",
    "resume_df, md = create_df(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['machine learning', 'r', 'data science', 'python', 'deep learning', 'natural language processing', 'tableau', 'sql', 'predictive modeling', 'statistics', 'data analysis', 'data visualization', 'statistical modeling', 'tensorflow', 'predictive analytics', 'artificial intelligence', 'data mining', 'scikit-learn', 'data analytics', 'apache', 'spark', 'big data', 'hadoop', 'algorithms', 'git', 'amazon web services', 'big data analytics', 'hive', 'scala', 'matlab', 'pandas', 'numpy', 'sas', 'microsoft power bi', 'nlp', 'aws', 'ai', 'mathmatics', 'data scientist', 'b.e/b.tech/m.e/m.tech/ms', 'computer science', '3-6 years', 'advanced computer vision', 'keras', 'yolo', 'caffe', 'high dimension classifiers', 'advanced techniques', 'gcp', 'python flask\\nadditional information'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.keywords.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3-6 years',\n",
       " 'advanced computer vision',\n",
       " 'advanced techniques',\n",
       " 'b.e/b.tech/m.e/m.tech/ms',\n",
       " 'caffe',\n",
       " 'computer science',\n",
       " 'deep learning',\n",
       " 'gcp',\n",
       " 'high dimension classifiers',\n",
       " 'keras',\n",
       " 'machine learning',\n",
       " 'python',\n",
       " 'python flask\\nadditional information',\n",
       " 'tensorflow',\n",
       " 'yolo'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_keyword_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py:1166: RuntimeWarning: invalid value encountered in true_divide\n",
      "  similarities = dot_products / (norm * all_norms)\n"
     ]
    }
   ],
   "source": [
    "from model import resume_scorer\n",
    "# Make sure to reload everytime\n",
    "importlib.reload(resume_scorer)\n",
    "ResumeScorer = resume_scorer.ResumeScorer\n",
    "\n",
    "scorer: ResumeScorer = ResumeScorer(job)\n",
    "scored = scorer.score_resume_as_dataframe(resume_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>scoring_text</th>\n",
       "      <th>score</th>\n",
       "      <th>duration</th>\n",
       "      <th>raw_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>certifications</td>\n",
       "      <td>Neural Networks and Deep Learning</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deep learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>certifications</td>\n",
       "      <td>Triplebyte Certified Data Scientist</td>\n",
       "      <td>0.456379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[triplebyte certified data scientist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contactInfo</td>\n",
       "      <td>Monica Music</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[monica music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education</td>\n",
       "      <td>Doctor of Philosophy (Ph.D.), Information Syst...</td>\n",
       "      <td>0.222112</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[information systems for, stem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education</td>\n",
       "      <td>Bachelor of Science - BS, Mechanical Engineering</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>48.0</td>\n",
       "      <td>[bachelor of science - bs, mechanical engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experience</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1.014000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[data scientist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experience</td>\n",
       "      <td>Data Scientist Developing data mining solution...</td>\n",
       "      <td>0.321525</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[data scientist developing, decision support s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience</td>\n",
       "      <td>Graduate Research Assistant In my research, I ...</td>\n",
       "      <td>0.301502</td>\n",
       "      <td>59.0</td>\n",
       "      <td>[graduate research, machine learning, nltk &amp; g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experience</td>\n",
       "      <td>Quantitative Methods Fellow Teaching courses i...</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[quantitative methods, business analytics, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>experience</td>\n",
       "      <td>Data Science Intern I was using the company's ...</td>\n",
       "      <td>1.666000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[machine learning, python, sas, 42%, sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>experience</td>\n",
       "      <td>Master Thesis Writer Used Keras and YOLO in em...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[yolo, gcp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>projects</td>\n",
       "      <td>Suppliers Learning: Aggregate and Individual L...</td>\n",
       "      <td>0.694324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[suppliers learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>projects</td>\n",
       "      <td>Role of interaction quality and trust in use o...</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ai]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summary</td>\n",
       "      <td>With a Ph.D. in data science and more than fiv...</td>\n",
       "      <td>0.269406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[more than five years]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type                                       scoring_text  \\\n",
       "30  certifications                 Neural Networks and Deep Learning    \n",
       "29  certifications               Triplebyte Certified Data Scientist    \n",
       "1      contactInfo                                       Monica Music   \n",
       "11       education  Doctor of Philosophy (Ph.D.), Information Syst...   \n",
       "13       education  Bachelor of Science - BS, Mechanical Engineering    \n",
       "2       experience                                    Data Scientist    \n",
       "3       experience  Data Scientist Developing data mining solution...   \n",
       "4       experience  Graduate Research Assistant In my research, I ...   \n",
       "5       experience  Quantitative Methods Fellow Teaching courses i...   \n",
       "6       experience  Data Science Intern I was using the company's ...   \n",
       "8       experience  Master Thesis Writer Used Keras and YOLO in em...   \n",
       "22        projects  Suppliers Learning: Aggregate and Individual L...   \n",
       "23        projects  Role of interaction quality and trust in use o...   \n",
       "0          summary  With a Ph.D. in data science and more than fiv...   \n",
       "\n",
       "       score  duration                                       raw_keywords  \n",
       "30  1.770000       NaN                                    [deep learning]  \n",
       "29  0.456379       NaN              [triplebyte certified data scientist]  \n",
       "1        inf       NaN                                     [monica music]  \n",
       "11  0.222112      60.0                    [information systems for, stem]  \n",
       "13  0.302949      48.0  [bachelor of science - bs, mechanical engineer...  \n",
       "2   1.014000       6.0                                   [data scientist]  \n",
       "3   0.321525       9.0  [data scientist developing, decision support s...  \n",
       "4   0.301502      59.0  [graduate research, machine learning, nltk & g...  \n",
       "5   0.762447       9.0  [quantitative methods, business analytics, dat...  \n",
       "6   1.666000       6.0          [machine learning, python, sas, 42%, sql]  \n",
       "8   0.900000       5.0                                        [yolo, gcp]  \n",
       "22  0.694324       NaN                               [suppliers learning]  \n",
       "23  0.430000       NaN                                               [ai]  \n",
       "0   0.269406       NaN                             [more than five years]  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(resume_scorer)\n",
    "\n",
    "cut, stats = resume_scorer.shorten_resume(scored, kw)\n",
    "\n",
    "print(len(scored))\n",
    "print(len(cut))\n",
    "cut[['type', 'scoring_text', 'score', 'duration', 'raw_keywords' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"contactInfo\": {\"address\": \"Chicago, IL\", \"website\": \"my-website.com\", \"linkedin\": \"linkedin.com/in/me123\", \"name\": \"Monica Music\", \"phoneNumber\": \"01012345\", \"email\": \"monica@music.co.kr\", \"github\": \"monicamusic123\", \"birthday\": \"24 December 1985\", \"family\": \"5 kids, divorced\", \"keywords\": [[\"monica music\", 1.0]], \"raw_keywords\": [\"monica music\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": Infinity, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": Infinity}, \"summary\": {\"value\": \"With a Ph.D. in data science and more than five years of working in data science and analytical roles, I have significant experience in creating actionable insights and data-driven solutions through research, experimentation, data analysis, and developing advanced analytical and machine learning models. I collaborated with different teams and managed cross- functional projects to provide innovative solutions to challenging problems and advise executives on operations, product, marketing, and customer experience strategies.\", \"label\": 0.26940578982065133, \"keywords\": [[\"more than five years\", 1.0]], \"raw_keywords\": [\"more than five years\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.26940578982065133}, \"experience\": {\"value\": [{\"value\": {\"company\": \"Apple\", \"title\": \"Data Scientist\", \"location\": \"San Francisco\", \"fromDate\": \"June 2022\", \"toDate\": \"Present\", \"description\": \"\", \"duration\": 6.0, \"time_since\": 0.0, \"keywords\": [[\"data scientist\", 1.0]], \"raw_keywords\": [\"data scientist\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.014, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 1.014}, \"label\": 1.0}, {\"value\": {\"company\": \"iRobot\", \"title\": \"Data Scientist\", \"location\": \"Boston\", \"fromDate\": \"August 2021\", \"toDate\": \"May 2022\", \"description\": \"Developing data mining solutions to create practical insights for optimizing Direct-to-Customer plans and activities. Improving product quality by analyzing customer and product data to identify issues and improvement areas. Built a 52% more accurate demand and sales forecasting model through better model selection and feature engineering. Producing dashboards and Decision Support Systems to help stakeholders in data-driven decision-making\", \"duration\": 9.0, \"time_since\": 7.0, \"keywords\": [[\"data scientist developing\", 1.0], [\"decision support systems\", 1.0]], \"raw_keywords\": [\"data scientist developing\", \"decision support systems\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.32152466745014485}, \"label\": 0.32152466745014485}, {\"value\": {\"company\": \"UMass Boston College of Management\", \"title\": \"Graduate Research Assistant\", \"location\": \"Boston\", \"fromDate\": \"September 2016\", \"toDate\": \"August 2021\", \"description\": \"In my research, I design experiments, conduct exploratory data analysis, apply statistical methods, and develop Machine Learning models to study human behaviors and to produce results with practical insights of value in a business context. Built an ML pipeline to predict online review effectiveness through personalization and feature engineering with NLP (Python). Applied NLP to extract new features through sentiment analysis and topic modeling (NLTK & Gensim). Developed XGBoost, Random Forest, and Poisson Regression (log-linear) models to predict customers decision. Developed and enhanced time series and RNN models of sequential human decisions through behavioral modeling (Python). Built and tuned ARIMA and LSTM models using new behavioral features and improved prediction RMSE by 5.8% (statsmodels & sklearn & keras). Developed a stock market portfolio recommender model using cluster analysis and association rule mining (R & SQL).\", \"duration\": 59.0, \"time_since\": 16.0, \"keywords\": [[\"graduate research\", 1.0], [\"machine learning\", 1.0], [\"nltk & gensim\", 1.0], [\"xgboost\", 1.0], [\"random forest\", 1.0], [\"poisson regression\", 1.0], [\"rnn\", 1.0], [\"python\", 1.0], [\"5.8%\", 1.0], [\"statsmodels & sklearn & keras\", 1.0]], \"raw_keywords\": [\"graduate research\", \"machine learning\", \"nltk & gensim\", \"xgboost\", \"random forest\", \"poisson regression\", \"rnn\", \"python\", \"5.8%\", \"statsmodels & sklearn & keras\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.30150173466172203}, \"label\": 0.30150173466172203}, {\"value\": {\"company\": \"Babson College\", \"title\": \"Quantitative Methods Fellow\", \"location\": \"Wellesley\", \"fromDate\": \"August 2020\", \"toDate\": \"May 2021\", \"description\": \"Teaching courses in Quantitative Methods, Business Analytics, Data Mining, and Statistical Learning\", \"duration\": 9.0, \"time_since\": 19.0, \"keywords\": [[\"quantitative methods, business analytics\", 1.0], [\"data mining\", 1.0], [\"statistical learning\", 1.0]], \"raw_keywords\": [\"quantitative methods, business analytics\", \"data mining\", \"statistical learning\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.7624471602398873}, \"label\": 0.7624471602398873}, {\"value\": {\"company\": \"Plymouth Rock Assurance\", \"title\": \"Data Science Intern\", \"location\": \"Boston\", \"fromDate\": \"July 2020\", \"toDate\": \"January 2021\", \"description\": \"I was using the company's big data to build advanced analytical solutions and Machine Learning models to improve the predictive performance of the risk and pricing models. Improved performance of the XGBoost model for price & risk prediction through feature engineering (Python, SAS). Decreased unmatched customer records by 42% by performing entity resolution (Python, SQL, SAS)\", \"duration\": 6.0, \"time_since\": 23.0, \"keywords\": [[\"machine learning\", 1.0], [\"python\", 1.0], [\"sas\", 1.0], [\"42%\", 1.0], [\"sql\", 1.0]], \"raw_keywords\": [\"machine learning\", \"python\", \"sas\", \"42%\", \"sql\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.014, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [\"machine learning\", \"python\"], \"keyword_cover_heuristic\": 1.0, \"score\": 1.666}, \"label\": 0.6519999999999999}, {\"value\": {\"company\": \"Trigo\", \"title\": \"Master Thesis Writer\", \"location\": \"Oslo\", \"fromDate\": \"January 2013\", \"toDate\": \"June 2013\", \"description\": \"Used Keras and YOLO in embedded systems to do object recognition in rounabouts. The results were sent to GCP where they where further analyzed with high dimension classifiers.\", \"duration\": 5.0, \"time_since\": 115.0, \"keywords\": [[\"yolo\", 1.0], [\"gcp\", 1.0]], \"raw_keywords\": [\"yolo\", \"gcp\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.8999999999999999}, \"label\": 0.8999999999999999}], \"label\": 0}, \"education\": {\"value\": [{\"value\": {\"title\": \"Doctor of Philosophy (Ph.D.), Information Systems for Data Science (STEM)\", \"location\": \"Boston\", \"fromDate\": \"2016\", \"toDate\": \"2021\", \"description\": \"\", \"duration\": 60.0, \"time_since\": 23.0, \"institution\": \"University of Massachusetts Boston\", \"keywords\": [[\"information systems for\", 1.0], [\"stem\", 1.0]], \"raw_keywords\": [\"information systems for\", \"stem\"], \"education_heuristic\": 0.03, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.2221123912924304}, \"label\": 0.1921123912924304}, {\"value\": {\"title\": \"Bachelor of Science - BS, Mechanical Engineering\", \"location\": \"Sharif\", \"fromDate\": \"2005\", \"toDate\": \"2009\", \"description\": \"\", \"duration\": 48.0, \"time_since\": 169.0, \"institution\": \"Sharif University of Technology\", \"keywords\": [[\"bachelor of science - bs\", 1.0], [\"mechanical engineering\", 1.0]], \"raw_keywords\": [\"bachelor of science - bs\", \"mechanical engineering\"], \"education_heuristic\": 0.03, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.3029493666221521}, \"label\": 0.27294936662215213}], \"label\": 0}, \"interests\": {\"value\": [], \"label\": 0}, \"accomplishments\": {\"value\": [], \"label\": 0}, \"languages\": {\"value\": [], \"label\": 0}, \"projects\": {\"value\": [{\"value\": {\"title\": \"Suppliers Learning: Aggregate and Individual Levels\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\", \"keywords\": [[\"suppliers learning\", 1.0]], \"raw_keywords\": [\"suppliers learning\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.6943241382695337}, \"label\": 0.6943241382695337}, {\"value\": {\"title\": \"Role of interaction quality and trust in use of AI-based voice-assistant systems\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\", \"keywords\": [[\"ai\", 1.0]], \"raw_keywords\": [\"ai\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.43}, \"label\": 0.43}], \"label\": 0}, \"softSkills\": {\"value\": [], \"label\": 0}, \"hardSkills\": {\"value\": [], \"label\": 0}, \"certifications\": {\"value\": [{\"value\": {\"title\": \"Neural Networks and Deep Learning\", \"description\": \"\", \"level\": \"\", \"date\": \"\", \"keywords\": [[\"deep learning\", 1.0]], \"raw_keywords\": [\"deep learning\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [\"deep learning\"], \"keyword_cover_heuristic\": 0.5, \"score\": 1.77}, \"label\": 1.27}, {\"value\": {\"title\": \"Triplebyte Certified Data Scientist\", \"description\": \"\", \"level\": \"\", \"date\": \"\", \"keywords\": [[\"triplebyte certified data scientist\", 1.0]], \"raw_keywords\": [\"triplebyte certified data scientist\"], \"education_heuristic\": 0.0, \"experience_heuristic\": 0.0, \"contact_heuristic\": 0.0, \"interest_heuristic\": 0.0, \"covered_keywords\": [], \"keyword_cover_heuristic\": 0.0, \"score\": 0.4563792055649674}, \"label\": 0.4563792055649674}], \"label\": 0}, \"patents\": {\"value\": [], \"label\": 0}, \"extracurriculars\": {\"value\": [], \"label\": 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from util.json_to_df import get_resume_dict_from_dataframe\n",
    "\n",
    "\n",
    "output_dict = get_resume_dict_from_dataframe(cut)\n",
    "# del output_dict['_id']\n",
    "print(json.dumps(output_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensorflow'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stats['missing_keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = cut[resume_df.columns]\n",
    "cut = cut.drop([\"keywords\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['value', 'label', 'type', 'address', 'website', 'linkedin', 'name',\n",
       "       'phoneNumber', 'email', 'github', 'birthday', 'family', 'company',\n",
       "       'title', 'location', 'fromDate', 'toDate', 'description', 'duration',\n",
       "       'time_since', 'institution', 'proficiency', 'level', 'date',\n",
       "       'scoring_text', 'multiplier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'# 56',\n",
       " '42%',\n",
       " '5.8%',\n",
       " 'ai',\n",
       " 'ai-based voice assistant systems:',\n",
       " 'approximately 450,000',\n",
       " 'bachelor of science - bs',\n",
       " 'bi',\n",
       " 'customer relationship management',\n",
       " 'data mining',\n",
       " 'data scientist',\n",
       " 'data scientist developing',\n",
       " \"dean's fellowship award for phd program\",\n",
       " 'decision support systems',\n",
       " 'deep learning',\n",
       " 'diploma',\n",
       " 'english',\n",
       " 'erp',\n",
       " 'gcp',\n",
       " 'graduate research',\n",
       " 'information systems for',\n",
       " 'machine learning',\n",
       " 'mathematics discipline',\n",
       " 'mechanical engineering',\n",
       " 'monica music',\n",
       " 'more than five years',\n",
       " 'national entrance exam of universities',\n",
       " 'nltk & gensim',\n",
       " 'persian',\n",
       " 'physics',\n",
       " 'poisson regression',\n",
       " 'python',\n",
       " 'quantitative methods, business analytics',\n",
       " 'random forest',\n",
       " 'rnn',\n",
       " 'sas',\n",
       " 'second',\n",
       " 'sql',\n",
       " 'sql & r',\n",
       " 'statistical inference',\n",
       " 'statistical learning',\n",
       " 'statsmodels & sklearn & keras',\n",
       " 'stem',\n",
       " 'suppliers learning',\n",
       " 'the interaction and trust',\n",
       " 'triplebyte certified data scientist',\n",
       " 'xgboost',\n",
       " 'yolo'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stats['all_original_keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "from util.json_to_df import get_resume_dict_from_dataframe\n",
    "import json\n",
    "\n",
    "output = get_resume_dict_from_dataframe(cut, md)\n",
    "del output[\"_id\"]\n",
    "\n",
    "json.dumps(output)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olav\n"
     ]
    }
   ],
   "source": [
    "text = \"Olav, like to eat cake for my brithday, and he knows vision transformers\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for v in doc.ents: \n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\": \"hejhej123\", \"title\": \"Data Scientist\", \"contactInfo\": {\"address\": \"Chicago, IL\", \"website\": \"my-website.com\", \"linkedin\": \"linkedin.com/in/me123\", \"name\": \"Monica Music\", \"phoneNumber\": \"01012345\", \"email\": \"monica@music.co.kr\", \"github\": \"monicamusic123\", \"birthday\": \"24 December 1985\", \"family\": \"5 kids, divorced\"}, \"summary\": {\"value\": \"With a Ph.D. in data science and more than five years of working in data science and analytical roles, I have significant experience in creating actionable insights and data-driven solutions through research, experimentation, data analysis, and developing advanced analytical and machine learning models. I collaborated with different teams and managed cross- functional projects to provide innovative solutions to challenging problems and advise executives on operations, product, marketing, and customer experience strategies.\", \"label\": 0}, \"experience\": {\"value\": [{\"value\": {\"company\": \"Apple\", \"title\": \"Data Scientist\", \"location\": \"San Francisco\", \"fromDate\": \"June 2022\", \"toDate\": \"Present\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"company\": \"iRobot\", \"title\": \"Data Scientist\", \"location\": \"Boston\", \"fromDate\": \"August 2021\", \"toDate\": \"May 2022\", \"description\": \"Developing data mining solutions to create practical insights for optimizing Direct-to-Customer plans and activities. Improving product quality by analyzing customer and product data to identify issues and improvement areas. Built a 52% more accurate demand and sales forecasting model through better model selection and feature engineering. Producing dashboards and Decision Support Systems to help stakeholders in data-driven decision-making\"}, \"label\": 0}, {\"value\": {\"company\": \"UMass Boston College of Management\", \"title\": \"Graduate Research Assistant\", \"location\": \"Boston\", \"fromDate\": \"September 2016\", \"toDate\": \"August 2021\", \"description\": \"In my research, I design experiments, conduct exploratory data analysis, apply statistical methods, and develop Machine Learning models to study human behaviors and to produce results with practical insights of value in a business context. Built an ML pipeline to predict online review effectiveness through personalization and feature engineering with NLP (Python). Applied NLP to extract new features through sentiment analysis and topic modeling (NLTK & Gensim). Developed XGBoost, Random Forest, and Poisson Regression (log-linear) models to predict customers decision. Developed and enhanced time series and RNN models of sequential human decisions through behavioral modeling (Python). Built and tuned ARIMA and LSTM models using new behavioral features and improved prediction RMSE by 5.8% (statsmodels & sklearn & keras). Developed a stock market portfolio recommender model using cluster analysis and association rule mining (R & SQL).\"}, \"label\": 0}, {\"value\": {\"company\": \"Babson College\", \"title\": \"Quantitative Methods Fellow\", \"location\": \"Wellesley\", \"fromDate\": \"August 2020\", \"toDate\": \"May 2021\", \"description\": \"Teaching courses in Quantitative Methods, Business Analytics, Data Mining, and Statistical Learning\"}, \"label\": 0}, {\"value\": {\"company\": \"Plymouth Rock Assurance\", \"title\": \"Data Science Intern\", \"location\": \"Boston\", \"fromDate\": \"July 2020\", \"toDate\": \"January 2021\", \"description\": \"I was using the company's big data to build advanced analytical solutions and Machine Learning models to improve the predictive performance of the risk and pricing models. Improved performance of the XGBoost model for price & risk prediction through feature engineering (Python, SAS). Decreased unmatched customer records by 42% by performing entity resolution (Python, SQL, SAS)\"}, \"label\": 0}, {\"value\": {\"company\": \"Hamrahe Aval (MCI)\", \"title\": \"Product Development Specialist\", \"location\": \"Tehran\", \"fromDate\": \"February 2016\", \"toDate\": \"August 2016\", \"description\": \"I was responsible for improving business performance by building analytical models and tools to create data-driven business solutions and data-informed strategies. Developed machine learning models to predict customer lifetime value and churn using big data of customers and market (R). Built predictive models and created plans based on their results to maximize productivity and minimize costs (SQL & R). Managed cross-functional project of business process improvement and ERP system development. Designed and developed BI dashboards and a Decision Support System for data-driven decision-making: Developed a fully in-house system to address the company's specific needs in terms of financial management, provider network management, customer relationship management (CRM), and operations management.\"}, \"label\": 0}, {\"value\": {\"company\": \"Trigo\", \"title\": \"Master Thesis Writer\", \"location\": \"Oslo\", \"fromDate\": \"January 2013\", \"toDate\": \"June 2013\", \"description\": \"Used Keras and YOLO in embedded systems to do object recognition in rounabouts. The results were sent to GCP where they where further analyzed with high dimension classifiers.\"}, \"label\": 0}, {\"value\": {\"company\": \"FANAP\", \"title\": \"Business Intelligence Specialist\", \"location\": \"Tehran\", \"fromDate\": \"September 2011\", \"toDate\": \"December 2012\", \"description\": \"I was responsible for improving business performance by building analytical models and tools to create data-driven business solutions and data-informed strategies. Designed and developed BI dashboards as well as fully in-house system to address the company\\u2019s specific needs in terms of financial management, provider network management, customer relationship management (CRM), and operations management\"}, \"label\": 0}, {\"value\": {\"company\": \"Pdhco - Print & Design\", \"title\": \"Product and Market Development Specialist\", \"location\": \"Tehran\", \"fromDate\": \"September 2011\", \"toDate\": \"December 2012\", \"description\": \"I was responsible for growing the company's revenue and its market share by creating data-driven insights that help the company improve its marketing strategies and product-market fit.\"}, \"label\": 0}], \"label\": 0}, \"education\": {\"value\": [{\"value\": {\"institution\": \"University of Massachusetts Boston\", \"location\": \"Boston\", \"title\": \"Doctor of Philosophy (Ph.D.), Information Systems for Data Science (STEM)\", \"fromDate\": \"2016\", \"toDate\": \"2021\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"institution\": \"Sharif University of Technology\", \"location\": \"Sharif\", \"title\": \"Master of Business Administration (MBA)\", \"fromDate\": \"2011\", \"toDate\": \"2013\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"institution\": \"Sharif University of Technology\", \"location\": \"Sharif\", \"title\": \"Bachelor of Science - BS, Mechanical Engineering\", \"fromDate\": \"2005\", \"toDate\": \"2009\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"institution\": \"Shahid Beheshti High School\", \"location\": \"USA\", \"title\": \"Diploma in Physics and Mathematics Discipline\", \"fromDate\": \"2001\", \"toDate\": \"2005\", \"description\": \"\"}, \"label\": 0}], \"label\": 0}, \"interests\": {\"value\": [], \"label\": 0}, \"accomplishments\": {\"value\": [{\"value\": {\"title\": \"Ranked # 56 among approximately 450,000 participants in National Entrance Exam of Universities\", \"fromDate\": \"\", \"toDate\": \"\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Best PhD Student Presentation Award\", \"fromDate\": \"\", \"toDate\": \"\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Best Paper Award in Application of Theory\", \"fromDate\": \"\", \"toDate\": \"\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Second Best PhD Student Presentation Award\", \"fromDate\": \"\", \"toDate\": \"\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Dean's Fellowship Award for PhD Program\", \"fromDate\": \"\", \"toDate\": \"\", \"description\": \"\"}, \"label\": 0}], \"label\": 0}, \"languages\": {\"value\": [{\"value\": {\"name\": \"English\", \"proficiency\": 5}, \"label\": 0}, {\"value\": {\"name\": \"Persian\", \"proficiency\": 5}, \"label\": 0}], \"label\": 0}, \"projects\": {\"value\": [{\"value\": {\"title\": \"Suppliers Learning: Aggregate and Individual Levels\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Role of interaction quality and trust in use of AI-based voice-assistant systems\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"The Behavioral Effects of Competition Intensity and Cost Structure on Competing Suppliers: An Experimental Study in the Context of the USA\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"AI-Based Voice Assistant Systems: Evaluating from the Interaction and Trust Perspectives\", \"fromDate\": \"2021-05-20\", \"toDate\": \"2022-01-01\", \"description\": \"\"}, \"label\": 0}], \"label\": 0}, \"softSkills\": {\"value\": [], \"label\": 0}, \"hardSkills\": {\"value\": [{\"value\": {\"name\": \"Statistical Inference\", \"proficiency\": 5}, \"label\": 0}, {\"value\": {\"name\": \"Predictive Modelling\", \"proficiency\": 5}, \"label\": 0}, {\"value\": {\"name\": \"Experimentation\", \"proficiency\": 3}, \"label\": 0}], \"label\": 0}, \"certifications\": {\"value\": [{\"value\": {\"title\": \"Triplebyte Certified Data Scientist\", \"level\": \"\", \"description\": \"\", \"date\": \"\"}, \"label\": 0}, {\"value\": {\"title\": \"Neural Networks and Deep Learning\", \"level\": \"\", \"description\": \"\", \"date\": \"\"}, \"label\": 0}], \"label\": 0}, \"patents\": {\"value\": [], \"label\": 0}, \"extracurriculars\": {\"value\": [], \"label\": 0}, \"description\": \"Data Scientist (Computer Vision) engineer\\n\\nFull-time\\nCompany Description\\nWe are an Artificial Intelligence (AI) focused product engineering company, providing our customers in healthcare, retail & e-commerce, manufacturing and hospitality sectors with cutting edge products & solutions, harnessing Big Data Analytics, Vision Analytics, and IoT.\\nEver since our inception in March 2010, Tech Vedika has been a partner of choice for several clients in US, Canada, Middle East and APAC. We were listed as one of the Top 10 Healthcare Analytics Solution Provider for year 2019' by Healthcare Tech Outlook Magazine.\\nWe strive for simple, elegant tech solutions to perform complex tasks. As a scalable technology partner, we enable organizations to improve operational efficiency and unleash new business potential\\nThe Data Scientist (Computer Vision) engineer will be required to build and implement algorithms based on our existing product portfolio and develop cutting-edge solutions for the emerging requirements of our key markets. \\n\\nJob Description\\nThe Data Scientist (Computer Vision) engineer will have the opportunity to interact and collaborate with our team of Tech Vedika (WARETRAC) experts in developing cutting-edge solutions to meet the dynamic nature of requirements for our customers. \\n\\nKey Responsibilities: \\n    \\u2022 Designing and implementing efficient computer vision algorithms for recognizing, tracking subjects within a controlled environment \\n    \\u2022 Architecting algorithms to work onboard our hardware systems as well as in the cloud where appropriate. \\n    \\u2022 Work together with our software development team to develop a scalable software solution \\n    \\u2022 Qualifications\\n\\n\\nRequired Experience:\\n\\n    \\u2022 B.E/B.Tech/M.E/M.Tech/MS in Computer Science, Applied Mathematics, or a related field. \\n    \\u2022 Minimum of 3-6 years of Relevant experience \\n    \\u2022 Experience and exposure on Advanced Computer Vision, Image processing and Machine Learning \\n    \\u2022 Practical experience in frameworks such as TensorFlow, TensorFlow Lite, OpenVINO, Keras, Yolo, Caffe. \\n    \\u2022 Hands-on experience on Image segmentation, feature extraction, High Dimension Classifiers and object tracking algorithms \\n    \\u2022 Solid Experience with Python, preferably in a Linux environment \\n    \\u2022 Good problem-solving and diagnostic skills, in a fast-paced environment. \\n    \\u2022 Work experience on data structures, algorithms, and ability to rapidly prototype and evaluate algorithms \\n    \\u2022 Experience in optimization for computer vision  \\n    \\u2022 Ability to write efficient and maintainable code \\n    \\u2022 Good analytical, problem solving, and communication skills are essential as well as the ability to work collaboratively in a team environment. \\n\\nDesired Experience:\\n\\n    \\u2022 Prior experience in working with depth sensors and 3D Reconstruction using computer vision, image processing techniques \\n    \\u2022 Advanced Techniques in Computer vision and Deep Learning. \\n    \\u2022 Knowledge on any Cloud Technologies (AWS, Azure, GCP.)  \\n    \\u2022 Knowledge on any Reporting Tools  \\n    \\u2022 Understanding of REST API, JSON, Python Flask \\n    \\u2022 Additional Information\\n\\nAt Tech Vedika, we are looking for talented individuals who want to work with driven people. Attain success while working on interesting projects with a culturally diverse group of individuals.\\n\\nBenefits:\\n\\n    \\u2022 Multiple Health coverage\\n    \\u2022 Competitive salary for a growing organization \\n    \\u2022 Gain experience rapidly\\n    \\u2022 Work directly with executive team\\n    \\u2022 Fast-paced work environment\"}\n"
     ]
    }
   ],
   "source": [
    "o = {**resume, \"description\": job_description} \n",
    "\n",
    "print(json.dumps(o))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
